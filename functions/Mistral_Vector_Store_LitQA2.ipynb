{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a183da-e187-4ffe-a8f2-ea1b76ae5148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Progress: 99.99570095868621%%%%"
     ]
    }
   ],
   "source": [
    "from mistralai import Mistral\n",
    "import os\n",
    "import faiss\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "directory = \"/home/adrian/Documents/University Work/Part III Project/PaperQA2/LitQA2_Papers_Parsing\"\n",
    "\n",
    "mistral_client = Mistral(api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
    "\n",
    "def get_text_embedding(input):\n",
    "    embeddings_batch_response = mistral_client.embeddings.create(\n",
    "        model=\"mistral-embed\",\n",
    "        inputs=input\n",
    "    )\n",
    "    return embeddings_batch_response.data[0].embedding\n",
    "\n",
    "full_paths = [os.path.abspath(os.path.join(directory, f)) for f in os.listdir(directory)]\n",
    "chunks=[]\n",
    "for doc in (full_paths):\n",
    "    uploaded_pdf = mistral_client.files.upload(\n",
    "        file={\n",
    "            \"file_name\": \"uploaded_file.pdf\",\n",
    "            \"content\": open(doc, \"rb\"),\n",
    "        },\n",
    "        purpose=\"ocr\"\n",
    "    )\n",
    "    signed_url = mistral_client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
    "    ocr_response = mistral_client.ocr.process(\n",
    "        model=\"mistral-ocr-latest\",\n",
    "        document={\n",
    "            \"type\": \"document_url\",\n",
    "            \"document_url\": signed_url.url,\n",
    "        }\n",
    "    )\n",
    "    for i in range(len(ocr_response.pages)):\n",
    "        #default chunking strategy used by OpenAI file search\n",
    "        splitter = MarkdownTextSplitter(chunk_size=800, chunk_overlap=400)\n",
    "        chunks.extend(splitter.split_text(ocr_response.pages[i].markdown))\n",
    "text_embeddings=[]\n",
    "count=0\n",
    "for chunk in chunks:\n",
    "    print(\"Vector Store Progress: \"+str(count/len(chunks)*100)+\"%\", end=\"\\r\", flush=True)\n",
    "    count+=1\n",
    "    text_embeddings.append(get_text_embedding(chunk))\n",
    "    wait_time = random.random()\n",
    "    time.sleep(wait_time)\n",
    "text_embeddings = np.array(text_embeddings)\n",
    "\n",
    "np.save('text_embeddings_LitQA2.npy', text_embeddings)\n",
    "\n",
    "# Optionally, you might want to save the chunks as well for reference\n",
    "with open('chunks_LitQA2.txt', 'w', encoding='utf-8') as f:\n",
    "    for chunk in chunks:\n",
    "        f.write(chunk + '\\n---\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmbagent_env",
   "language": "python",
   "name": "cmbagent_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
