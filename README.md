# CosmoPaperQA
A dataset designed to test AI RAG (Retrieval Augmented Generation) for cosmology research applications, called CosmoPaperQA. Also includes a "proof of concept" AI evaluation algorithm that is designed to perform automated performance evaluation for complex research retrieval questions, like those which are included in the the CosmoPaperQA dataset.

The python code above uses the InspectAI framework to do performance evaluation using the CosmoPaperQA dataset. Evaluate_CosmoPaperQA_OpenAI.py uses the native OpenAI vector file stores (the vector store needs to be created seperately) and a simple OpenAI question answering agent to generate answers to the questions in CosmoPaperQA. Evaluate_CosmoPaperQA_PaperQA2.py uses PaperQA2 (https://github.com/Future-House/paper-qa) to generate the answers to the questions in CosmoPaperQA.

Libraries that are required for both python scripts are os (https://docs.python.org/3/library/os.html), openai (https://pypi.org/project/openai/), pydantic (https://pypi.org/project/pydantic/), numpy (https://pypi.org/project/numpy/), re (https://docs.python.org/3/library/re.html), rake_nltk (https://pypi.org/project/rake-nltk/), pylatexenc.latex2text (https://pypi.org/project/pylatexenc/), nltk (https://www.nltk.org/), json (https://docs.python.org/3/library/json.html), typing (https://docs.python.org/3/library/typing.html) and inspect_ai (https://inspect.aisi.org.uk/). Evaluate_CosmoPaperQA_PaperQA2.py additionally requires the paperqa library (https://github.com/Future-House/paper-qa).
